This project was develop as part of the Microsoft Innovation lab.
It had 3 components:
1. The Android App - This applied object detection algorithm on images to return the data of the surrounding.
2. Raspberry Pi Image click: This clicked pictures and sent the data to the Android App
3. Text to speech conversion: The result was then read out loud using festival